{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a Gordo workflow locally:\n",
    "\n",
    "This demonstrates the basic workflow of gordo, running locally.\n",
    "\n",
    "---\n",
    "\n",
    "### Import and initialize a Gordo dataset\n",
    "In this case we shall be using the `DataLakeProvider` where `InfluxDataProvider` is also available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-11-26 14:51:04,254] INFO [gordo_components.dataset.sensor_tag.normalize_sensor_tags:140] Normalizing list of sensors in some format into SensorTags: ['GRA-FIC -13-0041X.PV']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndata_provider = DataLakeProvider(storename=\"dataplatformdlsprod\", interactive=True)\\ndataset = TimeSeriesDataset(from_ts=dateutil.parser.isoparse(\\'2017-01-01T00:10:00+00:00\\'),\\n    to_ts=dateutil.parser.isoparse(\\'2017-01-10T00:00:00+00:00\\'),\\n    tag_list=[\\n        \\'asgb.19PST3925/DispMeasOut/PRIM\\'\\n    ],\\n    data_provider=data_provider)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dateutil.parser\n",
    "import yaml\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from gordo_components.dataset.datasets import TimeSeriesDataset\n",
    "from gordo_components.data_provider.providers import DataLakeProvider\n",
    "from gordo_components import serializer\n",
    "\n",
    "data_provider = DataLakeProvider(storename=\"dataplatformdlsdev\", interactive=True)\n",
    "dataset = TimeSeriesDataset(from_ts=dateutil.parser.isoparse('2018-01-01T00:10:00+00:00'),\n",
    "    to_ts=dateutil.parser.isoparse('2018-12-10T00:00:00+00:00'),\n",
    "    tag_list=[\n",
    "       \"GRA-FIC -13-0041X.PV\"\n",
    "    ],\n",
    "    asset=\"2000-emj\",\n",
    "    data_provider=data_provider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We'll need to login to Azure to authenticate the ability load data from the Data Lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-11-26 14:51:04,266] INFO [gordo_components.data_provider.azure_utils.get_datalake_token:34] Attempting to use interactive azure authentication\n",
      "[2019-11-26 14:51:04,267] DEBUG [adal-python.debug:121] 1b0c9d9c-202f-45a1-92e9-367c6ac44b7c - Authority:Performing instance discovery: ...\n",
      "[2019-11-26 14:51:04,268] DEBUG [adal-python.debug:121] 1b0c9d9c-202f-45a1-92e9-367c6ac44b7c - Authority:Performing static instance discovery\n",
      "[2019-11-26 14:51:04,268] DEBUG [adal-python.debug:121] 1b0c9d9c-202f-45a1-92e9-367c6ac44b7c - Authority:Authority validated via static instance discovery\n",
      "[2019-11-26 14:51:04,269] INFO [adal-python.info:114] 1b0c9d9c-202f-45a1-92e9-367c6ac44b7c - CodeRequest:Getting user code info.\n",
      "[2019-11-26 14:51:04,274] DEBUG [urllib3.connectionpool._new_conn:959] Starting new HTTPS connection (1): login.microsoftonline.com:443\n",
      "[2019-11-26 14:51:04,800] DEBUG [urllib3.connectionpool._make_request:437] https://login.microsoftonline.com:443 \"POST /common/oauth2/devicecode?api-version=1.0 HTTP/1.1\" 200 477\n",
      "[2019-11-26 14:51:04,803] DEBUG [adal-python.debug:121] 1b0c9d9c-202f-45a1-92e9-367c6ac44b7c - OAuth2Client:Get Device Code Server returned this correlation_id: 1b0c9d9c-202f-45a1-92e9-367c6ac44b7c\n",
      "[2019-11-26 14:51:04,804] DEBUG [adal-python.debug:121] 1b0c9d9c-202f-45a1-92e9-367c6ac44b7c - Authority:Instance discovery/validation has either already been completed or is turned off: ...\n",
      "[2019-11-26 14:51:04,805] INFO [adal-python.info:114] 1b0c9d9c-202f-45a1-92e9-367c6ac44b7c - TokenRequest:Getting a token via device code\n",
      "[2019-11-26 14:51:04,810] DEBUG [urllib3.connectionpool._new_conn:959] Starting new HTTPS connection (1): login.microsoftonline.com:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code DAVM5FGB9 to authenticate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-11-26 14:51:05,252] DEBUG [urllib3.connectionpool._make_request:437] https://login.microsoftonline.com:443 \"POST /common/oauth2/token HTTP/1.1\" 400 469\n",
      "[2019-11-26 14:51:10,259] DEBUG [urllib3.connectionpool._new_conn:959] Starting new HTTPS connection (1): login.microsoftonline.com:443\n",
      "[2019-11-26 14:51:10,701] DEBUG [urllib3.connectionpool._make_request:437] https://login.microsoftonline.com:443 \"POST /common/oauth2/token HTTP/1.1\" 400 469\n",
      "[2019-11-26 14:51:15,713] DEBUG [urllib3.connectionpool._new_conn:959] Starting new HTTPS connection (1): login.microsoftonline.com:443\n",
      "[2019-11-26 14:51:16,370] DEBUG [urllib3.connectionpool._make_request:437] https://login.microsoftonline.com:443 \"POST /common/oauth2/token HTTP/1.1\" 200 6959\n",
      "[2019-11-26 14:51:16,380] DEBUG [adal-python.debug:121] 1b0c9d9c-202f-45a1-92e9-367c6ac44b7c - OAuth2Client:Get token with device code Server returned this correlation_id: 1b0c9d9c-202f-45a1-92e9-367c6ac44b7c\n",
      "[2019-11-26 14:51:16,385] DEBUG [adal-python.debug:121] 1b0c9d9c-202f-45a1-92e9-367c6ac44b7c - TokenRequest:Storing retrieved token into cache\n",
      "[2019-11-26 14:51:16,390] DEBUG [adal-python.debug:121] 1b0c9d9c-202f-45a1-92e9-367c6ac44b7c - CacheDriver:Adding entry AccessTokenId: b'ifioUry+SC0o0tNkZT+ohluzLy40y7SAQ3SeEgwgBkc=', RefreshTokenId: b'o2X/va//y+eTt+ertV5WYVGxfzTd38QBUXFgyDfVoyw='\n",
      "[2019-11-26 14:51:16,392] DEBUG [adal-python.debug:121] 1b0c9d9c-202f-45a1-92e9-367c6ac44b7c - CacheDriver:Added entry is MRRT\n",
      "[2019-11-26 14:51:16,397] INFO [gordo_components.data_provider.ncs_reader.__init__:72] Starting NCS reader with 1 threads\n",
      "[2019-11-26 14:51:16,399] INFO [gordo_components.data_provider.iroc_reader.__init__:37] Starting IROC reader with 50 threads\n",
      "[2019-11-26 14:51:16,400] INFO [gordo_components.data_provider.ncs_reader.base_path_from_asset:210] Looking for match for asset 2000-emj\n",
      "[2019-11-26 14:51:16,401] INFO [gordo_components.data_provider.ncs_reader.base_path_from_asset:220] Found asset code 2000-emj, returning /transform/corporate/Aspen MS - IP21 Grane/sensordata/1755-GRA\n",
      "[2019-11-26 14:51:16,402] INFO [gordo_components.data_provider.providers.load_series_from_multiple_providers:59] Assigning tag: SensorTag(name='GRA-FIC -13-0041X.PV', asset='2000-emj') to reader <gordo_components.data_provider.ncs_reader.NcsReader object at 0x7f5dea8188d0>\n",
      "[2019-11-26 14:51:16,403] INFO [gordo_components.data_provider.providers.load_series_from_multiple_providers:71] Using tag reader <gordo_components.data_provider.ncs_reader.NcsReader object at 0x7f5dea8188d0> to fetch tags [SensorTag(name='GRA-FIC -13-0041X.PV', asset='2000-emj')]\n",
      "[2019-11-26 14:51:16,405] INFO [gordo_components.data_provider.ncs_reader.base_path_from_asset:210] Looking for match for asset 2000-emj\n",
      "[2019-11-26 14:51:16,406] INFO [gordo_components.data_provider.ncs_reader.base_path_from_asset:220] Found asset code 2000-emj, returning /transform/corporate/Aspen MS - IP21 Grane/sensordata/1755-GRA\n",
      "[2019-11-26 14:51:16,407] INFO [gordo_components.data_provider.ncs_reader.read_tag_files:163] Downloading tag: SensorTag(name='GRA-FIC -13-0041X.PV', asset='2000-emj') for years: range(2018, 2019)\n",
      "[2019-11-26 14:51:16,408] INFO [gordo_components.data_provider.ncs_reader.read_tag_files:171] Parsing file /transform/corporate/Aspen MS - IP21 Grane/sensordata/1755-GRA/GRA-FIC -13-0041X.PV/2018/GRA-FIC -13-0041X.PV_2018.parquet\n",
      "[2019-11-26 14:51:16,443] DEBUG [urllib3.connectionpool._new_conn:959] Starting new HTTPS connection (1): dataplatformdlsdev.azuredatalakestore.net:443\n",
      "[2019-11-26 14:51:16,818] DEBUG [urllib3.connectionpool._make_request:437] https://dataplatformdlsdev.azuredatalakestore.net:443 \"GET /webhdfs/v1/transform/corporate/Aspen%20MS%20-%20IP21%20Grane/sensordata/1755-GRA/GRA-FIC%20-13-0041X.PV/2018/GRA-FIC%20-13-0041X.PV_2018.parquet?OP=GETFILESTATUS&api-version=2018-09-01 HTTP/1.1\" 200 305\n",
      "[2019-11-26 14:51:16,820] INFO [gordo_components.data_provider.ncs_reader.read_tag_files:175] File size: 0.00MB\n",
      "[2019-11-26 14:51:16,869] DEBUG [urllib3.connectionpool._make_request:437] https://dataplatformdlsdev.azuredatalakestore.net:443 \"GET /webhdfs/v1/transform/corporate/Aspen%20MS%20-%20IP21%20Grane/sensordata/1755-GRA/GRA-FIC%20-13-0041X.PV/2018/GRA-FIC%20-13-0041X.PV_2018.parquet?OP=GETFILESTATUS&api-version=2018-09-01 HTTP/1.1\" 200 305\n",
      "[2019-11-26 14:51:17,150] DEBUG [urllib3.connectionpool._make_request:437] https://dataplatformdlsdev.azuredatalakestore.net:443 \"GET /webhdfs/v1//transform/corporate/Aspen%20MS%20-%20IP21%20Grane/sensordata/1755-GRA/GRA-FIC%20-13-0041X.PV/2018/GRA-FIC%20-13-0041X.PV_2018.parquet?OP=OPEN&api-version=2018-09-01&offset=0&length=683&read=true&filesessionid=6a6f76e9-853e-434b-8e20-73469dbde168 HTTP/1.1\" 200 None\n",
      "[2019-11-26 14:51:17,160] INFO [gordo_components.data_provider.ncs_reader.read_tag_files:191] Done parsing file /transform/corporate/Aspen MS - IP21 Grane/sensordata/1755-GRA/GRA-FIC -13-0041X.PV/2018/GRA-FIC -13-0041X.PV_2018.parquet\n",
      "[2019-11-26 14:51:17,160] INFO [azure.datalake.store.core.close:1282] closing stream\n",
      "[2019-11-26 14:51:17,163] DEBUG [root.join_timeseries:90] Appending NaN to GRA-FIC -13-0041X.PV at time 2018-01-01 00:10:00+00:00\n",
      "[2019-11-26 14:51:17,165] DEBUG [root.join_timeseries:108] Appending NaN to GRA-FIC -13-0041X.PV at time 2018-12-10 00:00:00+00:00\n",
      "[2019-11-26 14:51:17,165] DEBUG [root.join_timeseries:119] Head (3) and tail(3) of dataframe to be resampled:\n",
      "[2019-11-26 14:51:17,167] DEBUG [root.join_timeseries:120] 2018-01-01 00:10:00+00:00    NaN\n",
      "2018-08-29 07:03:45+00:00    0.0\n",
      "2018-08-29 07:08:16+00:00    0.0\n",
      "Name: GRA-FIC -13-0041X.PV, dtype: float64\n",
      "[2019-11-26 14:51:17,169] DEBUG [root.join_timeseries:121] 2018-08-29 08:06:49+00:00    0.0\n",
      "2018-08-29 08:11:20+00:00    0.0\n",
      "2018-12-10 00:00:00+00:00    NaN\n",
      "Name: GRA-FIC -13-0041X.PV, dtype: float64\n",
      "[2019-11-26 14:51:17,181] DEBUG [gordo_components.data_provider.providers.load_series_from_multiple_providers:77] Downloading all tags took 0.7772689630510285 seconds\n"
     ]
    }
   ],
   "source": [
    "X, y = dataset.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRA-FIC -13-0041X.PV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2018-08-29 07:00:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-08-29 07:10:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-08-29 07:20:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-08-29 07:30:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-08-29 07:40:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           GRA-FIC -13-0041X.PV\n",
       "2018-08-29 07:00:00+00:00                   0.0\n",
       "2018-08-29 07:10:00+00:00                   0.0\n",
       "2018-08-29 07:20:00+00:00                   0.0\n",
       "2018-08-29 07:30:00+00:00                   0.0\n",
       "2018-08-29 07:40:00+00:00                   0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a pipeline for model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/eimj/miniconda3/envs/gordo_components/lib/python3.7/site-packages/ipykernel_launcher.py:8: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \n",
      "[2019-11-26 14:04:43,216] DEBUG [gordo_components.serializer.pipeline_from_definition._build_step:115] Building step: {'sklearn.pipeline.Pipeline': {'steps': ['sklearn.preprocessing.data.MinMaxScaler', {'gordo_components.model.models.KerasAutoEncoder': {'kind': 'feedforward_hourglass'}}]}}\n",
      "[2019-11-26 14:04:43,217] DEBUG [gordo_components.serializer.pipeline_from_definition._build_step:115] Building step: sklearn.preprocessing.data.MinMaxScaler\n",
      "[2019-11-26 14:04:43,418] DEBUG [gordo_components.serializer.pipeline_from_definition._build_step:115] Building step: {'gordo_components.model.models.KerasAutoEncoder': {'kind': 'feedforward_hourglass'}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('step_0', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
       "                ('step_1', KerasAutoEncoder(kind='feedforward_hourglass'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = yaml.load(\n",
    "    \"\"\" \n",
    "    sklearn.pipeline.Pipeline:\n",
    "        steps:\n",
    "          - sklearn.preprocessing.data.MinMaxScaler\n",
    "          - gordo_components.model.models.KerasAutoEncoder:\n",
    "              kind: feedforward_hourglass\n",
    "    \"\"\"\n",
    ")\n",
    "pipe = serializer.pipeline_from_definition(config)\n",
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoEncoders were agreed to meet the specifications of a `Transformer`. Therefore, they do not implement a `predict` method.\n",
    "\n",
    "We shall then call `fit_transform` or `fit` -> `transform` if desired to treat datasets separately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/milg/Projects/gordo-components/venv/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype float32 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "26411/26411 [==============================] - 3s 110us/step - loss: 0.0015 - acc: 0.9846\n"
     ]
    }
   ],
   "source": [
    "pipe.fit(X, y=X.copy())  # Our target is just X\n",
    "xhat = pipe.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### `xhat` is now the auto-encoded result*\n",
    "\n",
    "*where the first half of each resulting sample was the _input_ to the model and secondhalf is the _output_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.32019111, 0.29786357, 0.32511118, 0.30381536],\n",
       "       [0.32019111, 0.29786357, 0.32511118, 0.30381536],\n",
       "       [0.32019111, 0.29786357, 0.32511118, 0.30381536],\n",
       "       ...,\n",
       "       [0.32429197, 0.26762422, 0.32392147, 0.27555713],\n",
       "       [0.32429197, 0.26762422, 0.32392147, 0.27555713],\n",
       "       [0.32450209, 0.26762422, 0.32392147, 0.27555713]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using custom or multiple aggregation methods\n",
    "TimeSeriesDataset supports customization of the aggregation method used for the resampled buckets, and it can even use multiple aggregation methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom aggregation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asgb.19ZT3950%2FY%2FPRIM</th>\n",
       "      <th>asgb.19PST3925%2FDispMeasOut%2FPRIM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-07-01 07:40:00+00:00</th>\n",
       "      <td>100.032417</td>\n",
       "      <td>46.330772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-01 07:50:00+00:00</th>\n",
       "      <td>100.032417</td>\n",
       "      <td>46.330772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-01 08:00:00+00:00</th>\n",
       "      <td>100.032417</td>\n",
       "      <td>46.330772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-01 08:10:00+00:00</th>\n",
       "      <td>100.032417</td>\n",
       "      <td>46.330772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-01 08:20:00+00:00</th>\n",
       "      <td>100.032417</td>\n",
       "      <td>46.330772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           asgb.19ZT3950%2FY%2FPRIM  \\\n",
       "2016-07-01 07:40:00+00:00                100.032417   \n",
       "2016-07-01 07:50:00+00:00                100.032417   \n",
       "2016-07-01 08:00:00+00:00                100.032417   \n",
       "2016-07-01 08:10:00+00:00                100.032417   \n",
       "2016-07-01 08:20:00+00:00                100.032417   \n",
       "\n",
       "                           asgb.19PST3925%2FDispMeasOut%2FPRIM  \n",
       "2016-07-01 07:40:00+00:00                            46.330772  \n",
       "2016-07-01 07:50:00+00:00                            46.330772  \n",
       "2016-07-01 08:00:00+00:00                            46.330772  \n",
       "2016-07-01 08:10:00+00:00                            46.330772  \n",
       "2016-07-01 08:20:00+00:00                            46.330772  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remember to load the first cell to have the required imports\n",
    "dataset = TimeSeriesDataset(from_ts=dateutil.parser.isoparse('2016-07-01T00:10:00+00:00'),\n",
    "    to_ts=dateutil.parser.isoparse('2017-01-01T00:00:00+00:00'),\n",
    "    tag_list=[\n",
    "        'asgb.19ZT3950%2FY%2FPRIM',\n",
    "        'asgb.19PST3925%2FDispMeasOut%2FPRIM'\n",
    "    ],\n",
    "    aggregation_methods=\"max\",\n",
    "    data_provider=data_provider)\n",
    "X, y = dataset.get_data()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple aggregation methods\n",
    "When using multiple aggregation methods the returned dataframe will have multi-level columns, with the tag-name as top-level  and aggregation method as the second level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>tag</th>\n",
       "      <th colspan=\"3\" halign=\"left\">asgb.19ZT3950%2FY%2FPRIM</th>\n",
       "      <th colspan=\"3\" halign=\"left\">asgb.19PST3925%2FDispMeasOut%2FPRIM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aggregation_method</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-07-01 07:40:00+00:00</th>\n",
       "      <td>100.032417</td>\n",
       "      <td>99.945984</td>\n",
       "      <td>99.989201</td>\n",
       "      <td>46.330772</td>\n",
       "      <td>46.327229</td>\n",
       "      <td>46.329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-01 07:50:00+00:00</th>\n",
       "      <td>100.032417</td>\n",
       "      <td>99.945984</td>\n",
       "      <td>99.989201</td>\n",
       "      <td>46.330772</td>\n",
       "      <td>46.327229</td>\n",
       "      <td>46.329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-01 08:00:00+00:00</th>\n",
       "      <td>100.032417</td>\n",
       "      <td>99.945984</td>\n",
       "      <td>99.989201</td>\n",
       "      <td>46.330772</td>\n",
       "      <td>46.327229</td>\n",
       "      <td>46.329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-01 08:10:00+00:00</th>\n",
       "      <td>100.032417</td>\n",
       "      <td>99.945984</td>\n",
       "      <td>99.989201</td>\n",
       "      <td>46.330772</td>\n",
       "      <td>46.327229</td>\n",
       "      <td>46.329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-01 08:20:00+00:00</th>\n",
       "      <td>100.032417</td>\n",
       "      <td>99.945984</td>\n",
       "      <td>99.989201</td>\n",
       "      <td>46.330772</td>\n",
       "      <td>46.327229</td>\n",
       "      <td>46.329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "tag                       asgb.19ZT3950%2FY%2FPRIM                        \\\n",
       "aggregation_method                             max        min       mean   \n",
       "2016-07-01 07:40:00+00:00               100.032417  99.945984  99.989201   \n",
       "2016-07-01 07:50:00+00:00               100.032417  99.945984  99.989201   \n",
       "2016-07-01 08:00:00+00:00               100.032417  99.945984  99.989201   \n",
       "2016-07-01 08:10:00+00:00               100.032417  99.945984  99.989201   \n",
       "2016-07-01 08:20:00+00:00               100.032417  99.945984  99.989201   \n",
       "\n",
       "tag                       asgb.19PST3925%2FDispMeasOut%2FPRIM             \\\n",
       "aggregation_method                                        max        min   \n",
       "2016-07-01 07:40:00+00:00                           46.330772  46.327229   \n",
       "2016-07-01 07:50:00+00:00                           46.330772  46.327229   \n",
       "2016-07-01 08:00:00+00:00                           46.330772  46.327229   \n",
       "2016-07-01 08:10:00+00:00                           46.330772  46.327229   \n",
       "2016-07-01 08:20:00+00:00                           46.330772  46.327229   \n",
       "\n",
       "tag                                \n",
       "aggregation_method           mean  \n",
       "2016-07-01 07:40:00+00:00  46.329  \n",
       "2016-07-01 07:50:00+00:00  46.329  \n",
       "2016-07-01 08:00:00+00:00  46.329  \n",
       "2016-07-01 08:10:00+00:00  46.329  \n",
       "2016-07-01 08:20:00+00:00  46.329  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remember to load the first cell to have the required imports\n",
    "dataset = TimeSeriesDataset(from_ts=dateutil.parser.isoparse('2016-07-01T00:10:00+00:00'),\n",
    "    to_ts=dateutil.parser.isoparse('2017-01-01T00:00:00+00:00'),\n",
    "    tag_list=[\n",
    "        'asgb.19ZT3950%2FY%2FPRIM',\n",
    "        'asgb.19PST3925%2FDispMeasOut%2FPRIM'\n",
    "    ],\n",
    "    aggregation_methods=[\"max\",\"min\",\"mean\"],\n",
    "    data_provider=data_provider)\n",
    "X, y = dataset.get_data()\n",
    "X.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
